Help on built-in function estimatePoseSingleMarkers:

eessttiimmaatteePPoosseeSSiinngglleeMMaarrkkeerrss(...)
    estimatePoseSingleMarkers(corners, markerLength, cameraMatrix, distCoeffs[, rvecs[, tvecs[, _objPoints[, estimateParameters]]]]) -> rvecs, tvecs, _objPoints
    .   * @brief Pose estimation for single markers
    .    *
    .    * @param corners vector of already detected markers corners. For each marker, its four corners
    .    * are provided, (e.g std::vector<std::vector<cv::Point2f> > ). For N detected markers,
    .    * the dimensions of this array should be Nx4. The order of the corners should be clockwise.
    .    * @sa detectMarkers
    .    * @param markerLength the length of the markers' side. The returning translation vectors will
    .    * be in the same unit. Normally, unit is meters.
    .    * @param cameraMatrix input 3x3 floating-point camera matrix
    .    * \f$A = \vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\f$
    .    * @param distCoeffs vector of distortion coefficients
    .    * \f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6],[s_1, s_2, s_3, s_4]])\f$ of 4, 5, 8 or 12 elements
    .    * @param rvecs array of output rotation vectors (@sa Rodrigues) (e.g. std::vector<cv::Vec3d>).
    .    * Each element in rvecs corresponds to the specific marker in imgPoints.
    .    * @param tvecs array of output translation vectors (e.g. std::vector<cv::Vec3d>).
    .    * Each element in tvecs corresponds to the specific marker in imgPoints.
    .    * @param _objPoints array of object points of all the marker corners
    .    * @param estimateParameters set the origin of coordinate system and the coordinates of the four corners of the marker
    .    * (default estimateParameters.pattern = PatternPos::CCW_center, estimateParameters.useExtrinsicGuess = false,
    .    * estimateParameters.solvePnPMethod = SOLVEPNP_ITERATIVE).
    .    *
    .    * This function receives the detected markers and returns their pose estimation respect to
    .    * the camera individually. So for each marker, one rotation and translation vector is returned.
    .    * The returned transformation is the one that transforms points from each marker coordinate system
    .    * to the camera coordinate system.
    .    * The marker coordinate system is centered on the middle (by default) or on the top-left corner of the marker,
    .    * with the Z axis perpendicular to the marker plane.
    .    * estimateParameters defines the coordinates of the four corners of the marker in its own coordinate system (by default) are:
    .    * (-markerLength/2, markerLength/2, 0), (markerLength/2, markerLength/2, 0),
    .    * (markerLength/2, -markerLength/2, 0), (-markerLength/2, -markerLength/2, 0)
    .    * @sa use cv::drawFrameAxes to get world coordinate system axis for object points
    .    * @sa @ref tutorial_aruco_detection
    .    * @sa EstimateParameters
    .    * @sa PatternPos
